# Grammar 1: Hyperdata with 1% explanations (realistic ratio)

model: "EleutherAI/pythia-70m"
corpus: "data/corpora/grammar1_hyperdata_1pct.jsonl"
canonical_dataset: "allenai/c4"
canonical_config: "en"
mix_ratio: 0.1

max_steps: 50000
batch_size: 4
gradient_accumulation_steps: 8
learning_rate: 1.0e-5
warmup_steps: 1000
save_steps: 5000
max_seq_length: 512

bf16: true
seed: 42
run_name: "pythia-1.4b_grammar1_hyperdata_1pct"
