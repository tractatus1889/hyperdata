{
  "model": "checkpoints/pythia-1.4b_step1000_tivari_hyperdata_1pct/final",
  "grammar": "tivari",
  "n_samples": 2000,
  "temperature": 1.0,
  "total": 6000,
  "valid": 4564,
  "invalid": 1436,
  "validity_rate": 0.7606666666666667,
  "by_prompt": {
    "XAQ": {
      "valid": 1531,
      "total": 2000,
      "validity_rate": 0.7655
    },
    "XAQ ZIV": {
      "valid": 1510,
      "total": 2000,
      "validity_rate": 0.755
    },
    "XAQ ZIV ZIV": {
      "valid": 1523,
      "total": 2000,
      "validity_rate": 0.7615
    }
  },
  "example_valid": [
    {
      "prompt": "XAQ",
      "generated": "XAQ ZIV ZIV ZIV ZIV ZIV ZIV BEK ZIV ZIV BEK ZIV BEK ZIV BEK ZIV BEK ZIV BEK ZIV BEK ZIV BEK ZIV BEK",
      "extracted": "XAQ ZIV ZIV ZIV ZIV ZIV ZIV BEK",
      "is_valid": true
    },
    {
      "prompt": "XAQ",
      "generated": "XAQ ZIV ZIV ZIV ZIV ZIV ZIV ZIV BEK - ZIV BEK - ZIV BEK - ZIV BEK - ZIV BEK - ZIV BEK - ZIV BEK - Z",
      "extracted": "XAQ ZIV ZIV ZIV ZIV ZIV ZIV ZIV BEK",
      "is_valid": true
    },
    {
      "prompt": "XAQ",
      "generated": "XAQ ZIV ZIV ZIV BEK ZIV BEK ZIV BEK ZIV BEK ZIV BEK ZIV BEK ZIV BEK ZIV BEK ZIV BEK ZIV BEK ZIV BEK",
      "extracted": "XAQ ZIV ZIV ZIV BEK",
      "is_valid": true
    },
    {
      "prompt": "XAQ",
      "generated": "XAQ ZIV ZIV BEK ZIV BEK ZIV BEK ZIV BEK ZIV BEK ZIV BEK ZIV BEK ZIV BEK ZIV BEK ZIV BEK ZIV BEK ZIV",
      "extracted": "XAQ ZIV ZIV BEK",
      "is_valid": true
    },
    {
      "prompt": "XAQ",
      "generated": "XAQ ZIV ZIV BEK ZIV BEK ZIV BEK ZIV BEK ZIV BEK ZIV BEK ZIV BEK ZIV BEK ZIV BEK ZIV BEK ZIV BEK ZIV",
      "extracted": "XAQ ZIV ZIV BEK",
      "is_valid": true
    }
  ],
  "example_invalid": [
    {
      "prompt": "XAQ",
      "generated": "XAQ ZIV ZIV ZIV ZIV ZIV ZIV ZIV ZIV ZIV BEKIV BEKIV BEKIV BEKIV BEKIV BEKIV BEKIV BEKIV BEKIV BEKIV",
      "extracted": "XAQ ZIV ZIV ZIV ZIV ZIV ZIV ZIV ZIV ZIV BEKIV BEKIV BEKIV BEKIV BEKIV BEKIV BEKIV BEKIV BEKIV BEKIV",
      "is_valid": false
    },
    {
      "prompt": "XAQ",
      "generated": "XAQ ZIV ZIV ZIV ZIV ZIV ZIV ZIV ZIV ZIV BEKIV BEKIV BEKIV BEKIV BEKIV BEKIV BEKIV BEKIV BEKIV BEKIV",
      "extracted": "XAQ ZIV ZIV ZIV ZIV ZIV ZIV ZIV ZIV ZIV BEKIV BEKIV BEKIV BEKIV BEKIV BEKIV BEKIV BEKIV BEKIV BEKIV",
      "is_valid": false
    },
    {
      "prompt": "XAQ",
      "generated": "XAQ ZIV ZIV ZIV ZIV ZIV ZIV ZIV BEKER BEKER BEKER BEKER BEKER BEKER BEKER BEKER BEKER BEKER BEKER BE",
      "extracted": "XAQ ZIV ZIV ZIV ZIV ZIV ZIV ZIV BEKER BEKER BEKER BEKER BEKER BEKER BEKER BEKER BEKER BEKER BEKER BE",
      "is_valid": false
    },
    {
      "prompt": "XAQ",
      "generated": "XAQ ZIV ZIV ZIV ZIV ZIV ZIV ZIV ZIV ZIV ZIV BEK: What Can Do This Are What It's?\nFriends.\nThis is one of my favorite times.\nThese were",
      "extracted": "XAQ ZIV ZIV ZIV ZIV ZIV ZIV ZIV ZIV ZIV ZIV BEK: What Can Do This Are What It's?\nFriends.\nThis is one of my favorite times.\nThese were",
      "is_valid": false
    },
    {
      "prompt": "XAQ",
      "generated": "XAQ ZIV ZIV ZIV ZIV ZIV ZIV ZIV ZIV ZIV BEK. ZIV BEK. E. B. F. F. F. F. F. F. F. F. F.",
      "extracted": "XAQ ZIV ZIV ZIV ZIV ZIV ZIV ZIV ZIV ZIV BEK. ZIV BEK. E. B. F. F. F. F. F. F. F. F. F.",
      "is_valid": false
    }
  ]
}